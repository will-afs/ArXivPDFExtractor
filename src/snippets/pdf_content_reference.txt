Journal of Arti(cid:12)cial Intelligence Research 1 (1993) 25-46

Submitted 7/93; published 8/93

Dynamic Backtracking

Matthew L. Ginsberg

ginsberg@cs.uoregon.edu

CIRL, University of Oregon,

Eugene, OR 97403-1269 USA

Abstract

Because of their occasional need to return to shallow points in a search tree, existing

backtracking methods can sometimes erase meaningful progress toward solving a search

problem.

In this paper, we present a method by which backtrack points can be moved

deeper in the search space, thereby avoiding this di(cid:14)culty. The technique developed is

a variant of dependency-directed backtracking that uses only polynomial space while still

providing useful control information and retaining the completeness guarantees provided

by earlier approaches.

1. Introduction

Imagine that you are trying to solve some constraint-satisfaction problem, or csp. In the

interests of de(cid:12)niteness, I will suppose that the csp in question involves coloring a map of

the United States sub ject to the restriction that adjacent states be colored di(cid:11)erently.

Imagine we begin by coloring the states along the Mississippi, thereby splitting the

remaining problem in two. We now begin to color the states in the western half of the

country, coloring perhaps half a dozen of them before deciding that we are likely to be able

to color the rest. Suppose also that the last state colored was Arizona.

At this point, we change our focus to the eastern half of the country. After all, if we can't

color the eastern half because of our coloring choices for the states along the Mississippi,

there is no point in wasting time completing the coloring of the western states.

We successfully color the eastern states and then return to the west. Unfortunately, we

color New Mexico and Utah and then get stuck, unable to color (say) Nevada. What's more,

backtracking doesn't help, at least in the sense that changing the colors for New Mexico

and Utah alone does not allow us to proceed farther. Depth-(cid:12)rst search would now have

us backtrack to the eastern states, trying a new color for (say) New York in the vain hope

that this would solve our problems out West.

This is obviously pointless; the blockade along the Mississippi makes it impossible for

New York to have any impact on our attempt to color Nevada or other western states.

What's more, we are likely to examine every possible coloring of the eastern states before

addressing the problem that is actually the source of our di(cid:14)culties.

The solutions that have been proposed to this involve (cid:12)nding ways to backtrack directly

to some state that might actually allow us to make progress, in this case Arizona or earlier.

Dependency-directed backtracking (Stallman & Sussman, 1977) involves a direct backtrack

to the source of the di(cid:14)culty; backjumping (Gaschnig, 1979) avoids the computational over-

head of this technique by using syntactic methods to estimate the point to which backtrack

is necessary.

(cid:13)1993 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

c

Ginsberg

In both cases, however, note that although we backtrack to the source of the problem,

we backtrack over our successful solution to half of the original problem, discarding our

solution to the problem of coloring the states in the East. And once again, the problem is

worse than this { after we recolor Arizona, we are in danger of solving the East yet again

before realizing that our new choice for Arizona needs to be changed after all. We won't

examine every possible coloring of the eastern states, but we are in danger of rediscovering

our successful coloring an exponential number of times.

This hardly seems sensible; a human problem solver working on this problem would

simply ignore the East if possible, returning directly to Arizona and proceeding. Only if the

states along the Mississippi needed new colors would the East be reconsidered { and even

then only if no new coloring could be found for the Mississippi that was consistent with the

eastern solution.

In this paper we formalize this technique, presenting a modi(cid:12)cation to conventional

search techniques that is capable of backtracking not only to the most recently expanded

node, but also directly to a node elsewhere in the search tree. Because of the dynamic way

in which the search is structured, we refer to this technique as dynamic backtracking.

A more speci(cid:12)c outline is as follows: We begin in the next section by introducing a

variety of notational conventions that allow us to cast both existing work and our new

ideas in a uniform computational setting. Section 3 discusses backjumping, an intermediate

between simple chronological backtracking and our ideas, which are themselves presented

in Section 4. An example of the dynamic backtracking algorithm in use appears in Section

5 and an experimental analysis of the technique in Section 6. A summary of our results and

suggestions for future work are in Section 7. All proofs have been deferred to an appendix

in the interests of continuity of exposition.

2. Preliminaries

De(cid:12)nition 2.1 By a constraint satisfaction problem (I ; V ; (cid:20)) we wil l mean a set I of vari-

ables; for each i 2 I , there is a set V

of possible values for the variable i. (cid:20) is a set of

i

constraints, each a pair (J; P ) where J = (j

; . . . ; j

) is an ordered subset of I and P is a

1

k

subset of V

(cid:2) (cid:1) (cid:1) (cid:1) (cid:2) V

.

j

1

j

k

A solution to the csp is a set v

of values for each of the variables in I such that v

2 V

i

i

i

for each i and for every constraint (J; P ) of the above form in (cid:20), (v

; . . . ; v

) 2 P .

j

j

1

k

In the example of the introduction, I is the set of states and V

is the set of possible

i

colors for the state i. For each constraint, the (cid:12)rst part of the constraint is a pair of adjacent

states and the second part is a set of allowable color combinations for these states.

Our basic plan in this paper is to present formal versions of the search algorithms

described in the introduction, beginning with simple depth-(cid:12)rst search and proceeding to

backjumping and dynamic backtracking. As a start, we make the following de(cid:12)nition of a

partial solution to a csp:

De(cid:12)nition 2.2 Let (I ; V ; (cid:20)) be a csp. By a partial solution to the csp we mean an ordered

subset J (cid:18) I and an assignment of a value to each variable in J .

26

Dynamic Backtracking

We wil l denote a partial solution by a tuple of ordered pairs, where each ordered pair

(i; v ) assigns the value v to the variable i. For a partial solution P , we wil l denote by P the

set of variables assigned values by P .

Constraint-satisfaction problems are solved in practice by taking partial solutions and

extending them by assigning values to new variables. In general, of course, not any value can

be assigned to a variable because some are inconsistent with the constraints. We therefore

make the following de(cid:12)nition:

De(cid:12)nition 2.3 Given a partial solution P to a csp, an eliminating explanation for a

variable i is a pair (v ; S ) where v 2 V

and S (cid:18) P . The intended meaning is that i

i

cannot take the value v because of the values already assigned by P to the variables in S .

An elimination mechanism (cid:15) for a csp is a function that accepts as arguments a partial

solution P , and a variable i 62 P . The function returns a (possibly empty) set (cid:15)(P; i) of

eliminating explanations for i.

For a set E of eliminating explanations, we will denote by

E the values that have been

b

identi(cid:12)ed as eliminated, ignoring the reasons given. We therefore denote by

(cid:15)(P; i) the set

b

of values eliminated by elements of (cid:15)(P; i).

Note that the above de(cid:12)nition is somewhat (cid:13)exible with regard to the amount of work

done by the elimination mechanism { all values that violate completed constraints might

be eliminated, or some amount of lookahead might be done. We will, however, make the

following assumptions about all elimination mechanisms:

1. They are correct. For a partial solution P , if the value v

62

(cid:15)(P; i), then every

i

b

constraint (S; T ) in (cid:20) with S (cid:18) P [ fig is satis(cid:12)ed by the values in the partial solution

and the value v

for i. These are the constraints that are complete after the value v

i

i

is assigned to i.

2. They are complete. Suppose that P is a partial solution to a csp, and there is some

solution that extends P while assigning the value v to i. If P

is an extension of P

0

with (v ; E ) 2 (cid:15)(P

; i), then

0

E \ (P

(cid:0) P ) 6= (cid:31)

(1)

0

In other words, whenever P can be successfully extended after assigning v to i but

0

0

P

cannot be, at least one element of P

(cid:0) P is identi(cid:12)ed as a possible reason for the

problem.

3. They are concise. For a partial solution P , variable i and eliminated value v , there

is at most a single element of the form (v ; E ) 2 (cid:15)(P; i). Only one reason is given why

the variable i cannot have the value v .

Lemma 2.4 Let (cid:15) be a complete elimination mechanism for a csp, let P be a partial solu-

tion to this csp and let i 62 P . Now if P can be successful ly extended to a complete solution

after assigning i the value v , then v 62

(cid:15)(P; i).

b

I apologize for the swarm of de(cid:12)nitions, but they allow us to give a clean description of

depth-(cid:12)rst search:

27

Ginsberg

Algorithm 2.5 (Depth-(cid:12)rst search) Given as inputs a constraint-satisfaction problem

and an elimination mechanism (cid:15):

1. Set P = (cid:31). P is a partial solution to the csp. Set E

= (cid:31) for each i 2 I ; E

is the

i

i

set of values that have been eliminated for the variable i.

2. If P = I , so that P assigns a value to every element in I , it is a solution to the

original problem. Return it. Otherwise, select a variable i 2 I (cid:0) P . Set E

=

(cid:15)(P; i),

i

b

the values that have been eliminated as possible choices for i.

3. Set S = V

(cid:0) E

, the set of remaining possibilities for i. If S is nonempty, choose an

i

i

element v 2 S . Add (i; v ) to P , thereby setting i's value to v , and return to step 2.

4. If S is empty, let (j; v

) be the last entry in P ; if there is no such entry, return failure.

j

Remove (j; v

) from P , add v

to E

, set i = j and return to step 3.

j

j

j

We have written the algorithm so that it returns a single answer to the csp; the modi-

(cid:12)cation to accumulate all such answers is straightforward.

The problem with Algorithm 2.5 is that it looks very little like conventional depth-(cid:12)rst

search, since instead of recording the unexpanded children of any particular node, we are

keeping track of the failed siblings of that node. But we have the following:

Lemma 2.6 At any point in the execution of Algorithm 2.5, if the last element of the partial

solution P assigns a value to the variable i, then the unexplored siblings of the current node

are those that assign to i the values in V

(cid:0) E

.

i

i

Proposition 2.7 Algorithm 2.5 is equivalent to depth-(cid:12)rst search and therefore complete.

As we have remarked, the basic di(cid:11)erence between Algorithm 2.5 and a more conven-

tional description of depth-(cid:12)rst search is the inclusion of the elimination sets E

. The

i

conventional description expects nodes to include pointers back to their parents; the sib-

lings of a given node are found by examining the children of that node's parent. Since we

will be reorganizing the space as we search, this is impractical in our framework.

It might seem that a more natural solution to this di(cid:14)culty would be to record not the

values that have been eliminated for a variable i, but those that remain to be considered.

The technical reason that we have not done this is that it is much easier to maintain

elimination information as the search progresses. To understand this at an intuitive level,

note that when the search backtracks, the conclusion that has implicitly been drawn is

that a particular node fails to expand to a solution, as opposed to a conclusion about the

currently unexplored portion of the search space. It should be little surprise that the most

e(cid:14)cient way to manipulate this information is by recording it in approximately this form.

3. Backjumping

How are we to describe dependency-directed backtracking or backjumping in this setting?

In these cases, we have a partial solution and have been forced to backtrack; these more

sophisticated backtracking mechanisms use information about the reason for the failure to

identify backtrack points that might allow the problem to be addressed. As a start, we need

to modify Algorithm 2.5 to maintain the explanations for the eliminated values:

28

Dynamic Backtracking

Algorithm 3.1 Given as inputs a constraint-satisfaction problem and an elimination mech-

anism (cid:15):

1. Set P = E

= (cid:31) for each i 2 I . E

is a set of eliminating explanations for i.

i

i

2. If P = I , return P . Otherwise, select a variable i 2 I (cid:0) P . Set E

= (cid:15)(P; i):

i

3. Set S = V

(cid:0)

E

. If S is nonempty, choose an element v 2 S . Add (i; v ) to P and

b

i

i

return to step 2.

4. If S is empty, let (j; v

) be the last entry in P ; if there is no such entry, return failure.

j

Remove (j; v

) from P . We must have

E

= V

, so that every value for i has been

j

i

i

b

eliminated; let E be the set of al l variables appearing in the explanations for each

eliminated value. Add (v

; E (cid:0) fj g) to E

, set i = j and return to step 3.

j

j

Lemma 3.2 Let P be a partial solution obtained during the execution of Algorithm 3.1,

and let i 2 P be a variable assigned a value by P . Now if P

(cid:18) P can be successful ly

0

extended to a complete solution after assigning i the value v but (v ; E ) 2 E

, we must have

i

E \ (P (cid:0) P

) 6= (cid:31)

0

In other words, the assignment of a value to some variable in P (cid:0)P

is correctly identi(cid:12)ed

0

as the source of the problem.

j

values by P .

Note that in step 4 of the algorithm, we could have added (v

; E \ P ) instead of (v

; E (cid:0)

j

j

fj g) to E

; either way, the idea is to remove from E any variables that are no longer assigned

In backjumping, we now simply change our backtrack method; instead of removing a

single entry from P and returning to the variable assigned a value prior to the problematic

variable i, we return to a variable that has actually had an impact on i. In other words, we

return to some variable in the set E .

Algorithm 3.3 (Backjumping) Given as inputs a constraint-satisfaction problem and an

elimination mechanism (cid:15):

1. Set P = E

= (cid:31) for each i 2 I .

i

2. If P = I , return P . Otherwise, select a variable i 2 I (cid:0) P . Set E

= (cid:15)(P; i):

i

3. Set S = V

(cid:0)

E

. If S is nonempty, choose an element v 2 S . Add (i; v ) to P and

b

i

i

return to step 2.

4. If S is empty, we must have

E

= V

. Let E be the set of al l variables appearing in

b

i

i

the explanations for each eliminated value.

5. If E = (cid:31), return failure. Otherwise, let (j; v

) be the last entry in P such that j 2 E .

j

Remove from P this entry and any entry fol lowing it. Add (v

; E \ P ) to E

, set i = j

j

j

and return to step 3.

29

Ginsberg

In step 5, we add (v

; E \ P ) to E

, removing from E any variables that are no longer

j

j

assigned values by P .

Proposition 3.4 Backjumping is complete and always expands fewer nodes than does depth-

(cid:12)rst search.

neighbors.

Let us have a look at this in our map-coloring example. If we have a partial coloring

P and are looking at a speci(cid:12)c state i, suppose that we denote by C the set of colors that

are obviously illegal for i because they con(cid:13)ict with a color already assigned to one of i's

One possible elimination mechanism returns as (cid:15)(P; i) a list of (c; P ) for each color

c 2 C that has been used to color a neighbor of i. This reproduces depth-(cid:12)rst search, since

we gradually try all possible colors but have no idea what went wrong when we need to

backtrack since every colored state is included in P . A far more sensible choice would take

(cid:15)(P; i) to be a list of (c; fng) where n is a neighbor that is already colored c. This would

ensure that we backjump to a neighbor of i if no coloring for i can be found.

If this causes us to backjump to another state j , we will add i's neighbors to the elim-

inating explanation for j 's original color, so that if we need to backtrack still further, we

consider neighbors of either i or j . This is as it should be, since changing the color of one of

i's other neighbors might allow us to solve the coloring problem by reverting to our original

choice of color for the state j .

We also have:

Proposition 3.5 The amount of space needed by backjumping is o(i

v ), where i = jI j is

2

the number of variables in the problem and v is the number of values for that variable with

the largest value set V

.

i

This result contrasts sharply with an approach to csps that relies on truth-maintenance

techniques to maintain a list of nogoods (de Kleer, 1986). There, the number of nogoods

found can grow linearly with the time taken for the analysis, and this will typically be

exponential in the size of the problem. Backjumping avoids this problem by resetting the

set E

of eliminating explanations in step 2 of Algorithm 3.3.

i

The description that we have given is quite similar to that developed in (Bruynooghe,

1981). The explanations there are somewhat coarser than ours, listing all of the variables

that have been involved in any eliminating explanation for a particular variable in the csp,

but the idea is essentially the same. Bruynooghe's eliminating explanations can be stored

in o(i

) space (instead of o(i

v )), but the associated loss of information makes the technique

2

2

less e(cid:11)ective in practice. This earlier work is also a description of backjumping only, since

intermediate information is erased as the search proceeds.

4. Dynamic backtracking

We (cid:12)nally turn to new results. The basic problem with Algorithm 3.3 is not that it back-

jumps to the wrong place, but that it needlessly erases a great deal of the work that has

been done thus far. At the very least, we can retain the values selected for variables that

are backjumped over, in some sense moving the backjump variable to the end of the partial

30

Dynamic Backtracking

solution in order to replace its value without modifying the values of the variables that

followed it.

There is an additional modi(cid:12)cation that will probably be clearest if we return to the

example of the introduction. Suppose that in this example, we color only some of the eastern

states before returning to the western half of the country. We reorder the variables in order

to backtrack to Arizona and eventually succeed in coloring the West without disturbing the

colors used in the East.

Unfortunately, when we return East backtracking is required and we (cid:12)nd ourselves

needing to change the coloring on some of the eastern states with which we dealt earlier.

The ideas that we have presented will allow us to avoid erasing our solution to the problems

out West, but if the search through the eastern states is to be e(cid:14)cient, we will need to

retain the information we have about the portion of the East's search space that has been

eliminated. After all, if we have determined that New York cannot be colored yellow, our

changes in the West will not reverse this conclusion { the Mississippi really does isolate one

section of the country from the other.

The machinery needed to capture this sort of reasoning is already in place. When we

backjump over a variable k, we should retain not only the choice of value for k, but also k's

elimination set. We do, however, need to remove from this elimination set any entry that

involves the eventual backtrack variable j , since these entries are no longer valid { they

depend on the assumption that j takes its old value, and this assumption is now false.

Algorithm 4.1 (Dynamic backtracking I) Given as inputs a constraint-satisfaction prob-

lem and an elimination mechanism (cid:15):

1. Set P = E

= (cid:31) for each i 2 I .

i

2. If P = I , return P . Otherwise, select a variable i 2 I (cid:0) P . Set E

= E

[ (cid:15)(P; i).

i

i

3. Set S = V

(cid:0)

E

. If S is nonempty, choose an element v 2 S . Add (i; v ) to P and

b

i

i

return to step 2.

4. If S is empty, we must have

E

= V

; let E be the set of al l variables appearing in the

b

i

i

explanations for each eliminated value.

5. If E = (cid:31), return failure. Otherwise, let (j; v

) be the last entry in P such that j 2 E .

j

Remove (j; v

) from P and, for each variable k assigned a value after j , remove from

j

E

any eliminating explanation that involves j . Set

k

E

= E

[ (cid:15)(P; j ) [ f(v

; E \ P )g

(2)

j

j

j

so that v

is eliminated as a value for j because of the values taken by variables in

j

E \ P . The inclusion of the term (cid:15)(P; j ) incorporates new information from variables

that have been assigned values since the original assignment of v

to j . Now set i = j

j

and return to step 3.

Theorem 4.2 Dynamic backtracking always terminates and is complete. It continues to

satisfy Proposition 3.5 and can be expected to expand fewer nodes than backjumping provided

that the goal nodes are distributed randomly in the search space.

31

Ginsberg

The essential di(cid:11)erence between dynamic and dependency-directed backtracking is that

the structure of our eliminating explanations means that we only save nogood information

based on the current values of assigned variables; if a nogood depends on outdated infor-

mation, we drop it. By doing this, we avoid the need to retain an exponential amount of

nogood information. What makes this technique valuable is that (as stated in the theorem)

termination is still guaranteed.

There is one trivial modi(cid:12)cation that we can make to Algorithm 4.1 that is quite useful

in practice. After removing the current value for the backtrack variable j , Algorithm 4.1

immediately replaces it with another. But there is no real reason to do this; we could

instead pick a value for an entirely di(cid:11)erent variable:

Algorithm 4.3 (Dynamic backtracking) Given as inputs a constraint-satisfaction prob-

lem and an elimination mechanism (cid:15):

1. Set P = E

= (cid:31) for each i 2 I .

i

2. If P = I , return P . Otherwise, select a variable i 2 I (cid:0) P . Set E

= E

[ (cid:15)(P; i).

i

i

3. Set S = V

(cid:0)

E

. If S is nonempty, choose an element v 2 S . Add (i; v ) to P and

b

i

i

return to step 2.

4. If S is empty, we must have

E

= V

; let E be the set of al l variables appearing in the

b

i

i

explanations for each eliminated value.

5. If E = (cid:31), return failure. Otherwise, let (j; v

) be the last entry in P that binds a

variable appearing in E . Remove (j; v

) from P and, for each variable k assigned

j

j

a value after j , remove from E

any eliminating explanation that involves j . Add

k

(v

; E \ P ) to E

and return to step 2.

j

j

5. An example

In order to make Algorithm 4.3 a bit clearer, suppose that we consider a small map-

coloring problem in detail. The map is shown in Figure 1 and consists of (cid:12)ve countries:

Albania, Bulgaria, Czechoslovakia, Denmark and England. We will assume (wrongly!) that

the countries border each other as shown in the (cid:12)gure, where countries are denoted by nodes

and border one another if and only if there is an arc connecting them.

In coloring the map, we can use the three colors red, yellow and blue. We will typically

abbreviate the country names to single letters in the obvious way.

We begin our search with Albania, deciding (say) to color it red. When we now look at

Bulgaria, no colors are eliminated because Albania and Bulgaria do not share a border; we

decide to color Bulgaria yellow. (This is a mistake.)

We now go on to consider Czechoslovakia; since it borders Albania, the color red is

eliminated. We decide to color Czechoslovakia blue and the situation is now this:

32

s

(cid:0)
s

@

s

Czechoslovakia

(cid:0)

Albania

(cid:0)

@

@

@

@

@

(cid:0)

(cid:0)

@

(cid:0)

(cid:0)

Bulgaria

Dynamic Backtracking

Denmark

s

(cid:0)@

(cid:0)

(cid:0)

@

(cid:0)

@

(cid:0)

@

@

(cid:0)

@

(cid:0)

@

(cid:0)

@

@(cid:0)

s

England

Figure 1: A small map-coloring problem

country

color

red

yellow blue

Albania

red

Bulgaria

yellow

Czechoslovakia

blue

A

Denmark

England

For each country, we indicate its current color and the eliminating explanations that mean

it cannot be colored each of the three colors (when such explanations exist). We now look

at Denmark.

Denmark cannot be colored red because of its border with Albania and cannot be colored

yellow because of its border with Bulgaria; it must therefore be colored blue. But now

England cannot be colored any color at all because of its borders with Albania, Bulgaria

and Denmark, and we therefore need to backtrack to one of these three countries. At this

point, the elimination lists are as follows:

country

color

red

yellow blue

Albania

red

Bulgaria

yellow

Czechoslovakia

blue

A

Denmark

blue

A

B

England

A

B

D

We backtrack to Denmark because it is the most recent of the three possibilities, and

begin by removing any eliminating explanation involving Denmark from the above table to

get:

33

Ginsberg

country

color

red

yellow blue

Albania

red

Bulgaria

yellow

Czechoslovakia

blue

A

Denmark

A

B

England

A

B

Next, we add to Denmark's elimination list the pair

(blue; fA; Bg)

This indicates correctly that because of the current colors for Albania and Bulgaria, Den-

mark cannot be colored blue (because of the subsequent dead end at England). Since every

color is now eliminated, we must backtrack to a country in the set fA; Bg. Changing

Czechoslovakia's color won't help and we must deal with Bulgaria instead. The elimination

lists are now:

country

color

red

yellow blue

Albania

red

Bulgaria

Czechoslovakia

blue

A

Denmark

A

B

A,B

England

A

B

We remove the eliminating explanations involving Bulgaria and also add to Bulgaria's elim-

ination list the pair

(yellow; A)

indicating correctly that Bulgaria cannot be colored yellow because of the current choice of

color for Albania (red).

The situation is now:

country

color

red

yellow blue

Albania

red

Czechoslovakia

blue

A

Bulgaria

A

Denmark

A

England

A

We have moved Bulgaria past Czechoslovakia to re(cid:13)ect the search reordering in the algo-

rithm. We can now complete the problem by coloring Bulgaria red, Denmark either yellow

or blue, and England the color not used for Denmark.

This example is almost trivially simple, of course; the thing to note is that when we

changed the color for Bulgaria, we retained both the blue color for Czechoslovakia and the

information indicating that none of Czechoslovakia, Denmark and England could be red.

In more complex examples, this information may be very hard-won and retaining it may

save us a great deal of subsequent search e(cid:11)ort.

Another feature of this speci(cid:12)c example (and of the example of the introduction as

well) is that the computational bene(cid:12)ts of dynamic backtracking are a consequence of

34

Dynamic Backtracking

the automatic realization that the problem splits into disjoint subproblems. Other authors

have also discussed the idea of applying divide-and-conquer techniques to csps (Seidel, 1981;

Zabih, 1990), but their methods su(cid:11)er from the disadvantage that they constrain the order in

which unassigned variables are assigned values, perhaps at odds with the common heuristic

of assigning values (cid:12)rst to those variables that are most tightly constrained. Dynamic

backtracking can also be expected to be of use in situations where the problem in question

does not split into two or more disjoint subproblems.

1

6. Experimentation

Dynamic backtracking has been incorporated into the crossword-puzzle generation program

described in (Ginsberg, Frank, Halpin, & Torrance, 1990), and leads to signi(cid:12)cant perfor-

mance improvements in that restricted domain. More speci(cid:12)cally, the method was tested

on the problem of generating 19 puzzles of sizes ranging from 2 (cid:2) 2 to 13 (cid:2) 13; each puzzle

was attempted 100 times using both dynamic backtracking and simple backjumping. The

dictionary was shu(cid:15)ed between solution attempts and a maximum of 1000 backtracks were

permitted before the program was deemed to have failed.

In both cases, the algorithms were extended to include iterative broadening (Ginsberg

& Harvey, 1992), the cheapest-(cid:12)rst heuristic and forward checking. Cheapest-(cid:12)rst has

also been called \most constrained (cid:12)rst" and selects for instantiation that variable with

the fewest number of remaining possibilities (i.e., that variable for which it is cheapest to

enumerate the possible values (Smith & Genesereth, 1985)). Forward checking prunes the

set of possibilities for crossing words whenever a new word is entered and constitutes our

experimental choice of elimination mechanism: at any point, words for which there is no legal

crossing word are eliminated. This ensures that no word will be entered into the crossword

if the word has no potential crossing words at some point. The cheapest-(cid:12)rst heuristic

would identify the problem at the next step in the search, but forward checking reduces

the number of backtracks substantially. The \least-constraining" heuristic (Ginsberg et al.,

1990) was not used; this heuristic suggests that each word slot be (cid:12)lled with the word that

minimally constrains the subsequent search. The heuristic was not used because it would

invalidate the technique of shu(cid:15)ing the dictionary between solution attempts in order to

gather useful statistics.

The table in Figure 2 indicates the number of successful solution attempts (out of 100)

for each of the two methods on each of the 19 crossword frames. Dynamic backtracking is

more successful in six cases and less successful in none.

With regard to the number of nodes expanded by the two methods, consider the data

presented in Figure 3, where we graph the average number of backtracks needed by the

two methods.

Although initially comparable, dynamic backtracking provides increasing

2

computational savings as the problems become more di(cid:14)cult. A somewhat broader set of

experiments is described in (Jonsson & Ginsberg, 1993) and leads to similar conclusions.

There are some examples in (Jonsson & Ginsberg, 1993) where dynamic backtracking

leads to performance degradation, however; a typical case appears in Figure 4.

In this

3

1. I am indebted to David McAllester for these observations.

2. Only 17 points are shown because no point is plotted where backjumping was unable to solve the problem.

3. The worst performance degradation observed was a factor of approximately 4.

35

Dynamic

Dynamic

Frame backtracking Backjumping Frame backtracking Backjumping

1

100

100

11

100

98

2

100

100

12

100

100

3

100

100

13

100

100

4

100

100

14

100

100

5

100

100

15

99

14

6

100

100

16

100

26

7

100

100

17

100

30

8

100

100

18

61

0

9

100

100

19

10

0

10

100

100

Figure 2: Number of problems solved successfully

400

dynamic

200

backtracking

r

r

r

r

r

r

r

r

r

r

rr

r

r

r

r

r

200

400

600

800

1000

backjumping

Figure 3: Number of backtracks needed

Ginsberg

36

Dynamic Backtracking

s

(cid:0)
s

a

a

a

A

a

B

(cid:0)

@

a

@

a

a

a

a

@

a

@

a

a

a

@

Region 1

s

(cid:0)

(cid:0)

(cid:0)

(cid:0)

(cid:0)

(cid:0)

a

a

@

a

a

@

a

@
a

s

Region 2

Figure 4: A di(cid:14)cult problem for dynamic backtracking

(cid:12)gure, we (cid:12)rst color A, then B , then the countries in region 1, and then get stuck in region

2.

need to.

We now presumably backtrack directly to B , leaving the coloring of region 1 alone. But

this may well be a mistake { the colors in region 1 will restrict our choices for B , perhaps

making the subproblem consisting of A, B and region 2 more di(cid:14)cult than it might be. If

region 1 were easy to color, we would have been better o(cid:11) erasing it even though we didn't

This analysis suggests that dependency-directed backtracking should also fare worse

on those coloring problems where dynamic backtracking has trouble, and we are currently

extending the experiments of (Jonsson & Ginsberg, 1993) to con(cid:12)rm this. If this conjecture

is borne out, a variety of solutions come to mind. We might, for example, record how

many backtracks are made to a node such as B in the above (cid:12)gure, and then use this to

determine that (cid:13)exibility at B is more important than retaining the choices made in region

1. The di(cid:14)culty of (cid:12)nding a coloring for region 1 can also be determined from the number

of backtracks involved in the search.

7. Summary

7.1 Why it works

There are two separate ideas that we have exploited in the development of Algorithm 4.3

and the others leading up to it. The (cid:12)rst, and easily the most important, is the notion

that it is possible to modify variable order on the (cid:13)y in a way that allows us to retain the

results of earlier work when backtracking to a variable that was assigned a value early in

the search.

37

Ginsberg

This reordering should not be confused with the work of authors who have suggested a

dynamic choice among the variables that remain to be assigned values (Dechter & Meiri,

1989; Ginsberg et al., 1990; P. Purdom & Robertson, 1981; Zabih & McAllester, 1988); we

are instead reordering the variables that have been assigned values in the search thus far.

Another way to look at this idea is that we have found a way to \erase" the value given

to a variable directly as opposed to backtracking to it. This idea has also been explored

by Minton et.al. in (Minton, Johnston, Philips, & Laird, 1990) and by Selman et.al. in

(Selman, Levesque, & Mitchell, 1992); these authors also directly replace values assigned

to variables in satis(cid:12)ability problems. Unfortunately, the heuristic repair method used is

incomplete because no dependency information is retained from one state of the problem

solver to the next.

There is a third way to view this as well. The space that we are examining is really a

graph, as opposed to a tree; we reach the same point by coloring Albania blue and then

Bulgaria red as if we color them in the opposite order. When we decide to backjump from a

particular node in the search space, we know that we need to back up until some particular

property of that node ceases to hold { and the key idea is that by backtracking along a

path other than the one by which the node was generated, we may be able to backtrack

only slightly when we would otherwise need to retreat a great deal. This observation is

interesting because it may well apply to problems other than csps. Unfortunately, it is not

clear how to guarantee completeness for a search that discovers a node using one path and

backtracks using another.

The other idea is less novel. As we have already remarked, our use of eliminating

explanations is quite similar to the use of nogoods in the atms community; the principal

di(cid:11)erence is that we attach the explanations to the variables they impact and drop them

when they cease to be relevant. (They might become relevant again later, of course.) This

avoids the prohibitive space requirements of systems that permanently cache the results of

their nogood calculations; this observation also may be extensible beyond the domain of

csps speci(cid:12)cally. Again, there are other ways to view this { Gashnig's notion of backmarking

(Gaschnig, 1979) records similar information about the reason that particular portions of a

search space are known not to contain solutions.

7.2 Future work

There are a variety of ways in which the techniques we have presented can be extended; in

this section, we sketch a few of the more obvious ones.

7.2.1 Backtracking to older culprits

One extension to our work involves lifting the restriction in Algorithm 4.3 that the variable

erased always be the most recently assigned member of the set E .

In general, we cannot do this while retaining the completeness of the search. Consider

the following example:

Imagine that our csp involves three variables, x, y and z , that can each take the value 0

or 1. Further, suppose that this csp has no solutions, in that after we pick any two values

for x and for y , we realize that there is no suitable choice for z .

38

Dynamic Backtracking

We begin by taking x = y = 0; when we realize the need to backtrack, we introduce the

nogood

the new nogood

and replace the value for y with y = 1.

This fails, too, but now suppose that we were to decide to backtrack to x, introducing

x = 0 (cid:27) y 6= 0

(3)

y = 1 (cid:27) x 6= 0

(4)

We change x's value to 1 and erase (3).

This also fails. We decide that y is the problem and change its value to 0, introducing

the nogood

x = 1 (cid:27) y 6= 1

but erasing (4). And when this fails, we are in danger of returning to x = y = 0, which we

eliminated at the beginning of the example. This loop may cause a modi(cid:12)ed version of the

dynamic backtracking algorithm to fail to terminate.

In terms of the proof of Theorem 4.2, the nogoods discovered already include information

about all assigned variables, so there is no di(cid:11)erence between (7) and (8). When we drop

(3) in favor of (4), we are no longer in a position to recover (3).

We can deal with this by placing conditions on the variables to which we choose to

backtrack; the conditions need to be de(cid:12)ned so that the proof of Theorem 4.2 continues to

4

hold.

Experimentation indicates that loops of the form we have described are extremely

rare in practice; it may also be possible to detect them directly and thereby retain more

substantial freedom in the choice of backtrack point.

This freedom of backtrack raises an important question that has not yet been addressed

in the literature: When backtracking to avoid a di(cid:14)culty of some sort, to where should one

backtrack?

Previous work has been constrained to backtrack no further than the most recent choice

that might impact the problem in question; any other decision would be both incomplete and

ine(cid:14)cient. Although an extension of Algorithm 4.3 need not operate under this restriction,

we have given no indication of how the backtrack point should be selected.

There are several easily identi(cid:12)ed factors that can be expected to bear on this choice.

The (cid:12)rst is that there remains a reason to expect backtracking to chronologically recent

choices to be the most e(cid:11)ective { these choices can be expected to have contributed to

the fewest eliminating explanations, and there is obvious advantage to retaining as many

eliminating explanations as possible from one point in the search to the next. It is pos-

sible, however, to simply identify that backtrack point that a(cid:11)ects the fewest number of

eliminating explanations and to use that.

Alternatively, it might be important to backtrack to the choice point for which there

will be as many new choices as possible; as an extreme example, if there is a variable i

for which every value other than its current one has already been eliminated for other

reasons, backtracking to i is guaranteed to generate another backtrack immediately and

should probably be avoided if possible.

4. Another solution appears in (McAllester, 1993).

39

Ginsberg

Finally, there is some measure of the \directness" with which a variable bears on a

problem. If we are unable to (cid:12)nd a value for a particular variable i, it is probably sensible

to backtrack to a second variable that shares a constraint with i itself, as opposed to some

variable that a(cid:11)ects i only indirectly.

How are these competing considerations to be weighed? I have no idea. But the frame-

work we have developed is interesting because it allows us to work on this question. In

more basic terms, we can now \debug" partial solutions to csps directly, moving laterally

through the search space in an attempt to remain as close to a solution as possible. This

sort of lateral movement seems central to human solution of di(cid:14)cult search problems, and

it is encouraging to begin to understand it in a formal way.

7.2.2 Dependency pruning

It is often the case that when one value for a variable is eliminated while solving a csp,

others are eliminated as well. As an example, in solving a scheduling problem a particular

choice of time (say t = 16) may be eliminated for a task A because there then isn't enough

time between A and a subsequent task B ; in this case, all later times can obviously be

eliminated for A as well.

Formalizing this can be subtle; after all, a later time for A isn't uniformly worse than an

earlier time because there may be other tasks that need to precede A and making A later

makes that part of the schedule easier. It's the problem with B alone that forces A to be

earlier; once again, the analysis depends on the ability to maintain dependency information

as the search proceeds.

We can formalize this as follows. Given a csp (I ; V ; (cid:20)), suppose that the value v has

been assigned to some i 2 I . Now we can construct a new csp (I

; V

; (cid:20)

) involving the

0

0

0

remaining variables I

= I (cid:0) fig, where the new set V

need not mention the possible values

0

0

i

0

V

for i, and where (cid:20)

is generated from (cid:20) by modifying the constraints to indicate that i

has been assigned the value v . We also make the following de(cid:12)nition:

De(cid:12)nition 7.1 Given a csp, suppose that i is a variable that has two possible values u and

v . We wil l say that v is stricter than u if every constraint in the csp induced by assigning

u to i is also a constraint in the csp induced by assigning i the value v .

The point, of course, is that if v is stricter than u is, there is no point to trying a

solution involving v once u has been eliminated. After all, (cid:12)nding such a solution would

involve satisfying all of the constraints in the v restriction, these are a superset of those in

the u restriction, and we were unable to satisfy the constraints in the u restriction originally.

The example with which we began this section now generalizes to the following:

Proposition 7.2 Suppose that a csp involves a set S of variables, and that we have a

partial solution that assigns values to the variables in some subset P (cid:18) S . Suppose further

that if we extend this partial solution by assigning the value u to a variable i 62 P , there is

no further extension to a solution of the entire csp. Now consider the csp involving the

variables in S (cid:0) P that is induced by the choices of values for variables in P . If v is stricter

than u as a choice of value for i in this problem, the original csp has no solution that both

assigns v to i and extends the given partial solution on P .

40

Dynamic Backtracking

This proposition isn't quite enough; in the earlier example, the choice of t = 17 for A

will not be stricter than t = 16 if there is any task that needs to be scheduled before A is.

We need to record the fact that B (which is no longer assigned a value) is the source of the

di(cid:14)culty. To do this, we need to augment the dependency information with which we are

working.

More precisely, when we say that a set of variables fx

g eliminates a value v for a variable

i

x, we mean that our search to date has allowed us to conclude that

where the v

are the current choices for the x

. We can obviously rewrite this as

i

i

(v

= x

) ^ (cid:1) (cid:1) (cid:1) ^ (v

= x

) (cid:27) v 6= x

1

1

k

k

(v

= x

) ^ (cid:1) (cid:1) (cid:1) ^ (v

= x

) ^ (v = x) (cid:27) F

(5)

1

1

k

k

where F indicates that the csp in question has no solution.

Let's be more speci(cid:12)c still, indicating in (5) exactly which csp has no solution:

(v

= x

) ^ (cid:1) (cid:1) (cid:1) ^ (v

= x

) ^ (v = x) (cid:27) F (I )

(6)

1

1

k

k

where I is the set of variables in the complete csp.

Now we can address the example with which we began this section; the csp that is

known to fail in an expression such as (6) is not the entire problem, but only a subset of it.

In the example, we are considering, the subproblem involves only the two tasks A and B .

In general, we can augment our nogoods to include information about the subproblems on

which they fail, and then measure strictness with respect to these restricted subproblems

only. In our example, this will indeed allow us to eliminate t = 17 from consideration as a

possible time for A.

The additional information stored with the nogoods doubles their size (we have to store a

second subset of the variables in the csp), and the variable sets involved can be manipulated

easily as the search proceeds. The cost involved in employing this technique is therefore that

of the strictness computation. This may be substantial given the data structures currently

used to represent csps (which typically support the need to check if a constraint has been

violated but little more), but it seems likely that compile-time modi(cid:12)cations to these data

structures can be used to make the strictness question easier to answer.

In scheduling

problems, preliminary experimental work shows that the idea is an important one; here,

too, there is much to be done.

The basic lesson of dynamic backtracking is that by retaining only those nogoods that

are still relevant given the partial solution with which we are working, the storage di(cid:14)culties

encountered by full dependency-directed methods can be alleviated. This is what makes

all of the ideas we have proposed possible { erasing values, selecting alternate backtrack

points, and dependency pruning. There are surely many other e(cid:11)ective uses for a practical

dependency maintenance system as well.

Acknowledgements

This work has been supported by the Air Force O(cid:14)ce of Scienti(cid:12)c Research under grant

number 92-0693 and by DARPA/Rome Labs under grant number F30602-91-C-0036. I

41

Ginsberg

would like to thank Rina Dechter, Mark Fox, Don Geddis, Will Harvey, Vipin Kumar,

Scott Roy and Narinder Singh for helpful comments on these ideas. Ari Jonsson and

David McAllester provided me invaluable assistance with the experimentation and proofs

respectively.

A. Proofs

of (cid:15) that

a contradiction.

Lemma 2.4 Let (cid:15) be a complete elimination mechanism for a csp, let P be a partial solution

to this csp and let i 62 P . Now if P can be successful ly extended to a complete solution after

assigning i the value v , then v 62

(cid:15)(P; i).

b

Proof. Suppose otherwise, so that (v ; E ) 2 (cid:15)(P; i). It follows directly from the completeness

E \ (P (cid:0) P ) 6= (cid:31)

Lemma 2.6 At any point in the execution of Algorithm 2.5, if the last element of the partial

solution P assigns a value to the variable i, then the unexplored siblings of the current node

are those that assign to i the values in V

(cid:0) E

.

i

i

Proof. We (cid:12)rst note that when we decide to assign a value to a new variable i in step 2

of the algorithm, we take E

=

(cid:15)(P; i) so that V

(cid:0) E

is the set of allowed values for this

b

i

i

i

variable. The lemma therefore holds in this case. The fact that it continues to hold through

each repetition of the loop in steps 3 and 4 is now a simple induction; at each point, we

add to E

the node that has just failed as a possible value to be assigned to i.

i

Proposition 2.7 Algorithm 2.5 is equivalent to depth-(cid:12)rst search and therefore complete.

Proof. This is an easy consequence of the lemma. Partial solutions correspond to nodes

in the search space.

Lemma 3.2 Let P be a partial solution obtained during the execution of Algorithm 3.1, and

let i 2 P be a variable assigned a value by P . Now if P

(cid:18) P can be successful ly extended

0

to a complete solution after assigning i the value v but (v ; E ) 2 E

, we must have

i

E \ (P (cid:0) P

) 6= (cid:31)

0

Proof. As in the proof of Lemma 2.6, we show that no step of Algorithm 3.1 can cause

Lemma 3.2 to become false.

That the lemma holds after step 2, where the search is extended to consider a new

variable, is an immediate consequence of the assumption that the elimination mechanism

is complete.

(cid:12)rst search.

In step 4, when we add (v

; E (cid:0) fj g) to the set of eliminating explanations for j , we

j

are simply recording the fact that the search for a solution with j set to v

failed because

j

we were unable to extend the solution to i. It is a consequence of the inductive hypothesis

that as long as no variable in E (cid:0) fj g changes, this conclusion will remain valid.

Proposition 3.4 Backjumping is complete and always expands fewer nodes than does depth-

42

Dynamic Backtracking

Proof. That fewer nodes are examined is clear; for completeness, it follows from Lemma

3.2 that the backtrack to some element of E in step 5 will always be necessary if a solution

Proposition 3.5 The amount of space needed by backjumping is o(i

v ), where i = jI j is

2

the number of variables in the problem and v is the number of values for that variable with

is to be found.

the largest value set V

.

i

Proof. The amount of space needed is dominated by the storage requirements of the elim-

ination sets E

; there are i of these. Each one might refer to each of the possible values for

j

a particular variable j ; the space needed to store the reason that the value j is eliminated

is at most jI j, since the reason is simply a list of variables that have been assigned values.

There will never be two eliminating explanations for the same variable, since (cid:15) is concise

and we never rebind a variable to a value that has been eliminated.

Theorem 4.2 Dynamic backtracking always terminates and is complete. It continues to

satisfy Proposition 3.5 and can be expected to expand fewer nodes than backjumping provided

that the goal nodes are distributed randomly in the search space.

Proof. There are four things we need to show: That dynamic backtracking needs o(i

v )

2

space, that it is complete, that it can be expected to expand fewer nodes than backjumping,

and that it terminates. We prove things in this order.

Space This is clear; the amount of space needed continues to be bounded by the structure

of the eliminating explanations.

Completeness This is also clear, since by Lemma 3.2, all of the eliminating explanations

retained in the algorithm are obviously still valid. The new explanations added in (2) are

also obviously correct, since they indicate that j cannot take the value v

as in backjumping

j

and that j also cannot take any values that are eliminated by the variables being backjumped

over.

over.

E(cid:14)ciency To see that we expect to expand fewer nodes, suppose that the subproblem

involving only the variables being jumped over has s solutions in total, one of which is given

by the existing variable assignments. Assuming that the solutions are distributed randomly

in the search space, there is at least a 1=s chance that this particular solution leads to a

solution of the entire csp; if so, the reordered search { which considers this solution earlier

than the other { will save the expense of either assigning new values to these variables or

repeating the search that led to the existing choices. The reordered search will also bene(cid:12)t

from the information in the nogoods that have been retained for the variables being jumped

Termination This is the most di(cid:14)cult part of the proof.

As we work through the algorithm, we will be generating (and then discarding) a variety

of eliminating explanations. Suppose that e is such an explanation, saying that j cannot

take the value v

because of the values currently taken by the variables in some set e

.

j

V

We will denote the variables in e

by x

; . . . ; x

and their current values by v

; . . . ; v

. In

V

1

k

1

k

declarative terms, the eliminating explanation is telling us that

(x

= v

) ^ (cid:1) (cid:1) (cid:1) ^ (x

= v

) (cid:27) j 6= v

(7)

1

1

k

k

j

43

Ginsberg

Dependency-directed backtracking would have us accumulate all of these nogoods; dynamic

backtracking allows us to drop any particular instance of (7) for which the antecedent is no

longer valid.

The reason that dependency-directed backtracking is guaranteed to terminate is that

the set of accumulated nogoods eliminates a monotonically increasing amount of the search

space. Each nogood eliminates a new section of the search space because the nature of the

search process is such that any node examined is consistent with the nogoods that have been

accumulated thus far; the process is monotonic because all nogoods are retained throughout

the search. These arguments cannot be applied to dynamic backtracking, since nogoods are

forgotten as the search proceeds. But we can make an analogous argument.

To do this, suppose that when we discover a nogood like (7), we record with it all of the

variables that precede the variable j in the partial order, together with the values currently

assigned to these variables. Thus an eliminating explanation becomes essentially a nogood

n of the form (7) together with a set S of variable/value pairs.

We now de(cid:12)ne a mapping (cid:21)(n; S ) that changes the antecedent of (7) to include assump-

tions about al l the variables bound in S , so that if S = fs

; v

g,

i

i

(cid:21)(n; S ) = [(s

= v

) ^ (cid:1) (cid:1) (cid:1) ^ (s

= v

) (cid:27) j 6= v

]

(8)

1

1

l

l

j

At any point in the execution of the algorithm, we denote by N the conjunction of the

modi(cid:12)ed nogoods of the form (8).

We now make the following claims:

1. For any eliminating explanation (n; S ), n j= (cid:21)(n; S ) so that (cid:21)(n; S ) is valid for the

problem at hand.

2. For any new eliminating explanation (n; S ), (cid:21)(n; S ) is not a consequence of N .

3. The deductive consequences of N grow monotonically as the dynamic backtracking

algorithm proceeds.

The theorem will follow from these three observations, since we will know that N is a valid

set of conclusions for our search problem and that we are once again making monotonic

progress toward eliminating the entire search space and concluding that the problem is

unsolvable.

That (cid:21)(n; S ) is a consequence of (n; S ) is clear, since the modi(cid:12)cation used to obtain

(8) from (7) involves strengthening that antecedent of (7). It is also clear that (cid:21)(n; S ) is

not a consequence of the nogoods already obtained, since we have added to the antecedent

only conditions that hold for the node of the search space currently under examination. If

(cid:21)(n; S ) were a consequence of the nogoods we had obtained thus far, this node would not

be being considered.

The last observation depends on the following lemma:

Lemma A.1 Suppose that x is a variable assigned a value by our partial solution and that

x appears in the antecedent of the nogood n in the pair (n; S ). Then if S

is the set of

0

variables assigned values no later than x, S

(cid:18) S .

0

44

Dynamic Backtracking

Proof. Consider a y 2 S

, and suppose that it were not in S . We cannot have y = x, since

0

y would then be mentioned in the nogood n and therefore in S . So we can suppose that

y is actually assigned a value earlier than x is. Now when (n; S ) was added to the set of

eliminating explanations, it must have been the case that x was assigned a value (since it

appears in the antecedent of n) but that y was not. But we also know that there was a

later time when y was assigned a value but x was not, since y precedes x in the current

partial solution. This means that x must have changed value at some point after (n; S ) was

added to the set of eliminating explanations { but (n; S ) would have been deleted when this

happened. This contradiction completes the proof.

Returning to the proof the Theorem 4.2, suppose that we eventually drop (n; S ) from

our collection of nogoods and that when we do so, the new nogood being added is (n

; S

). It

0

0

follows from the lemma that S

(cid:18) S . Since x

= v

is a clause in the antecedent of (cid:21)(n; S ), it

0

0

0

i

i

follows that (cid:21)(n

; S

) will imply the negation of the antecedent of (cid:21)(n; S ) and will therefore

imply (cid:21)(n; S ) itself. Although we drop (cid:21)(n; S ) when we drop the nogood (n; S ), (cid:21)(n; S )

continues to be entailed by the modi(cid:12)ed set N , the consequences of which are seen to be

growing monotonically.

References

Bruynooghe, M. (1981). Solving combinatorial search problems by intelligent backtracking.

Information Processing Letters, 12 (1), 36{39.

de Kleer, J. (1986). An assumption-based truth maintenance system. Arti(cid:12)cial Intel ligence,

28, 127{162.

Dechter, R., & Meiri, I. (1989). Experimental evaluation of preprocessing techniques in

constraint satisfaction problems. In Proceedings of the Eleventh International Joint

Conference on Arti(cid:12)cial Intel ligence, pp. 271{277.

Gaschnig, J. (1979). Performance measurement and analysis of certain search algorithms.

Tech. rep. CMU-CS-79-124, Carnegie-Mellon University.

Ginsberg, M. L., Frank, M., Halpin, M. P., & Torrance, M. C. (1990). Search lessons learned

from crossword puzzles. In Proceedings of the Eighth National Conference on Arti(cid:12)cial

Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Arti(cid:12)cial Intel ligence, 55,

Intel ligence, pp. 210{215.

367{383.

Jonsson, A. K., & Ginsberg, M. L. (1993). Experimenting with new systematic and non-

systematic search techniques. In Proceedings of the AAAI Spring Symposium on AI

and NP-Hard Problems Stanford, California.

McAllester, D. A. (1993). Partial order backtracking. Journal of Arti(cid:12)cial Intel ligence

Research, 1. Submitted.

Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale con-

straint satisfaction and scheduling problems using a heuristic repair method. In Pro-

ceedings of the Eighth National Conference on Arti(cid:12)cial Intel ligence, pp. 17{24.

45

Ginsberg

P. Purdom, C. B., & Robertson, E. (1981). Backtracking with multi-level dynamic search

rearrangement. Acta Informatica, 15, 99{114.

Seidel, R. (1981). A new method for solving constraint satisfaction problems. In Proceedings

of the Seventh International Joint Conference on Arti(cid:12)cial Intel ligence, pp. 338{342.

Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satis(cid:12)ability

problems. In Proceedings of the Tenth National Conference on Arti(cid:12)cial Intel ligence.

Smith, D. E., & Genesereth, M. R. (1985). Ordering conjunctive queries. Arti(cid:12)cial Intel li-

Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning and dependency-directed

backtracking in a system for computer-aided circuit analysis. Arti(cid:12)cial Intel ligence,

gence, 26 (2), 171{215.

9 (2), 135{196.

Zabih, R. (1990). Some applications of graph bandwidth to constraint satisfaction problems.

In Proceedings of the Eighth National Conference on Arti(cid:12)cial Intel ligence, pp. 46{51.

Zabih, R., & McAllester, D. A. (1988). A rearrangement search strategy for determining

propositional satis(cid:12)ability.

In Proceedings of the Seventh National Conference on

Arti(cid:12)cial Intel ligence, pp. 155{160.

46

